{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer-Learning-NLP-TF-Hub.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bonthusaireddy/guided_projects/blob/main/Transfer_Learning_NLP_TF_Hub.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOPcjnDDc5c7"
      },
      "source": [
        "<h2 align=left> Transfer Learning for NLP with TensorFlow Hub</h2>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgBRL1nR_jdt"
      },
      "source": [
        "This is a starter notebook for the guided project [Transfer Learning for NLP with TensorFlow Hub](https://www.coursera.org/projects/transfer-learning-nlp-tensorflow-hub/)\n",
        "\n",
        "A complete version of this notebook is available in the course resources.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ak95VdGNn3lJ"
      },
      "source": [
        "### Overview\n",
        "\n",
        "[TensorFlow Hub](https://tfhub.dev/) is a repository of pre-trained TensorFlow models.\n",
        "\n",
        "In this project, you will use pre-trained models from TensorFlow Hub with [`tf.keras`](https://www.tensorflow.org/api_docs/python/tf/keras) for text classification. Transfer learning makes it possible to save training resources and to achieve good model generalization even when training on a small dataset. In this project, we will demonstrate this by training with several different TF-Hub modules."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNNs4oBDoSf-"
      },
      "source": [
        "### Learning Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyoqkQFsoUzB"
      },
      "source": [
        "By the time you complete this project, you will be able to:\n",
        "\n",
        "- Use various pre-trained NLP text embedding models from TensorFlow Hub\n",
        "- Perform transfer learning to fine-tune models on your own text data\n",
        "- Visualize model performance metrics with [TensorBoard](https://www.tensorflow.org/tensorboard)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_BTLVEapAm0"
      },
      "source": [
        "### Prerequisites"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MAL1ZXnpCiF"
      },
      "source": [
        "In order to be successful with this project, it is assumed you are:\n",
        "\n",
        "- Competent in the Python programming language\n",
        "- Familiar with deep learning for Natural Language Processing (NLP)\n",
        "- Familiar with TensorFlow, and its Keras API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5d14nw7gpEth"
      },
      "source": [
        "### Contents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGRlcriNpJGO"
      },
      "source": [
        "This project/notebook consists of several Tasks.\n",
        "\n",
        "- **[Task 1]()**: Introduction to the Project.\n",
        "- **[Task 2]()**: Setup your TensorFlow and Colab Runtime\n",
        "- **[Task 3]()**: Download and Import the Quora Insincere Questions Dataset\n",
        "- **[Task 4]()**: TensorFlow Hub for Natural Language Processing\n",
        "- **[Task 5]()**: Define Function to Build and Compile Models\n",
        "- **[Task 6]()**: Define Function to Build and Compile Models(Continued...)\n",
        "- **[Task 7]()**: Train Various Text Classification Models\n",
        "- **[Task 8]()**: Compare Accuracy and Loss Curves\n",
        "- **[Task 9]()**: Fine-tuning Models from TF Hub\n",
        "- **[Task 10]()**: Train Bigger Models and Visualize Metrics with TensorBoard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAxib00jpYbS"
      },
      "source": [
        "## Task 2: Setup your TensorFlow and Colab Runtime."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIPs2VnspY9l"
      },
      "source": [
        "You will only be able to use the Colab Notebook after you save it to your Google Drive folder. Click on the File menu and select “Save a copy in Drive…\n",
        "\n",
        "![Copy to Drive](https://drive.google.com/uc?id=1CH3eDmuJL8WR0AP1r3UE6sOPuqq8_Wl7)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcz2wdA_pez8"
      },
      "source": [
        "### Check GPU Availability\n",
        "\n",
        "Check if your Colab notebook is configured to use Graphical Processing Units (GPUs). If zero GPUs are available, check if the Colab notebook is configured to use GPUs (Menu > Runtime > Change Runtime Type).\n",
        "\n",
        "![Hardware Accelerator Settings](https://drive.google.com/uc?id=1qrihuuMtvzXJHiRV8M7RngbxFYipXKQx)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwWXcwno4wB9",
        "outputId": "a79e2a7b-430b-4e9e-edfe-1019065d42f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Apr 10 13:54:34 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   66C    P8    11W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxB26qlms3qE",
        "outputId": "27056f77-e62a-4abc-821c-a170feab6ab8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "from  IPython import display\n",
        "\n",
        "import pathlib\n",
        "import shutil\n",
        "import tempfile\n",
        "\n",
        "!pip install -q git+https://github.com/tensorflow/docs\n",
        "\n",
        "import tensorflow_docs as tfdocs\n",
        "import tensorflow_docs.modeling\n",
        "import tensorflow_docs.plots\n",
        "\n",
        "print(\"Version: \", tf.__version__)\n",
        "print(\"Hub version: \", hub.__version__)\n",
        "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")\n",
        "\n",
        "logdir = pathlib.Path(tempfile.mkdtemp())/\"tensorboard_logs\"\n",
        "shutil.rmtree(logdir, ignore_errors=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▎                               | 10kB 24.3MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 21.1MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 11.4MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 9.2MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 7.6MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 8.1MB/s eta 0:00:01\r\u001b[K     |██▎                             | 71kB 7.9MB/s eta 0:00:01\r\u001b[K     |██▋                             | 81kB 8.1MB/s eta 0:00:01\r\u001b[K     |██▉                             | 92kB 7.8MB/s eta 0:00:01\r\u001b[K     |███▏                            | 102kB 6.8MB/s eta 0:00:01\r\u001b[K     |███▌                            | 112kB 6.8MB/s eta 0:00:01\r\u001b[K     |███▉                            | 122kB 6.8MB/s eta 0:00:01\r\u001b[K     |████▏                           | 133kB 6.8MB/s eta 0:00:01\r\u001b[K     |████▌                           | 143kB 6.8MB/s eta 0:00:01\r\u001b[K     |████▉                           | 153kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 163kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 174kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 184kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 194kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 204kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 215kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████                         | 225kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 235kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 245kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 256kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 266kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 276kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████                       | 286kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 296kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 307kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 317kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 327kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 337kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 348kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 358kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 368kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 378kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 389kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 399kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 409kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 419kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 430kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 440kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 450kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 460kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 471kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 481kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 491kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 501kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 512kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 522kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 532kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 542kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 552kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 563kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 573kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 583kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 593kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 604kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 614kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 624kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 634kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 645kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 655kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 665kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 675kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 686kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 696kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 706kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 716kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 727kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 737kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 747kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 757kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 768kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 778kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 788kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 798kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 808kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 819kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 829kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 839kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 849kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 860kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 870kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 880kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 890kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 901kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 911kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 921kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 931kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 942kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 952kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 962kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 972kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 983kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 993kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.0MB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.0MB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.0MB 6.8MB/s \n",
            "\u001b[?25h  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Version:  2.4.1\n",
            "Hub version:  0.11.0\n",
            "GPU is available\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6qe4NYUp0vU"
      },
      "source": [
        "## Task 3: Download and Import the Quora Insincere Questions Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnRK0VlaDChm"
      },
      "source": [
        "A downloadable copy of the [Quora Insincere Questions Classification data](https://www.kaggle.com/c/quora-insincere-questions-classification/data) can be found [https://archive.org/download/fine-tune-bert-tensorflow-train.csv/train.csv.zip](https://archive.org/download/fine-tune-bert-tensorflow-train.csv/train.csv.zip). Decompress and read the data into a pandas DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfF56xcgs8Eb",
        "outputId": "f673c8db-5bae-41d4-fa77-860fe47e633d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df = pd.read_csv('https://archive.org/download/fine-tune-bert-tensorflow-train.csv/train.csv.zip', compression='zip', low_memory=False)\n",
        "df.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1306122, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08kiCrj5tzcj",
        "outputId": "cdbde3cf-47a0-479f-9f11-50f153521979",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        }
      },
      "source": [
        "df['target'].plot(kind='hist', title='Target distribution')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f2e69a02510>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfWdbhfYs8Ha",
        "outputId": "439fb63f-2dbd-4ed0-cc98-aab0007211be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, remaining = train_test_split(df, random_state = 42, train_size=0.01, stratify=df.target.values)\n",
        "valid_df, _ = train_test_split(remaining, random_state=42, train_size=0.001, stratify=remaining.target.values)\n",
        "train_df.shape, valid_df.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((13061, 3), (1293, 3))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VX1UEsALs8J8",
        "outputId": "b6150977-c55a-4a4d-d3b5-5d2ab411f022",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_df.target.head(15).values"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_E6VWNTs8Mn",
        "outputId": "ede6d802-c68a-455e-fdc0-6a5d88c6f602",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_df.question_text.head(15).values"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['What is your experience living in Venezuela in the current crisis? (2018)',\n",
              "       'In which state/city the price of property is highest?',\n",
              "       'Do rich blacks also call poor whites, “White Trash”?',\n",
              "       'Should my 5 yr old son and 2 yr old daughter spend the summer with their father, after a domestic violent relationship?',\n",
              "       'Why do we have parents?',\n",
              "       'Do we experience ghost like Murphy did in Interstellar?',\n",
              "       'Are Estoniano women beautiful?',\n",
              "       'There was a Funny or Die video called Sensitivity Hoedown that got pulled. Does anyone know why?',\n",
              "       'Is it a good idea to go in fully mainstream classes, even if I have meltdowns that might disrupt people?',\n",
              "       'What classifies a third world country as such?',\n",
              "       'Is being a pilot safe?',\n",
              "       'Who is Illiteratendra Modi? Why does he keep with him a Rs 1 lakh pen?',\n",
              "       'Have modern management strategies such as Total supply Chain Management applied to education? Can they be?',\n",
              "       'Why are Lucky Charms considered good for you?',\n",
              "       'How many people in India use WhatsApp, Facebook, Twitter and Instagram?'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xrTfnrpKagt",
        "outputId": "1fd22366-7a0d-4684-f2e9-be67eea2964b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>question_text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>147144</th>\n",
              "      <td>1cc67025519a7e0d23a5</td>\n",
              "      <td>What is your experience living in Venezuela in...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>978379</th>\n",
              "      <td>bfabc9f014b5d3e1b08c</td>\n",
              "      <td>In which state/city the price of property is h...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>588051</th>\n",
              "      <td>73315f395204472d6afc</td>\n",
              "      <td>Do rich blacks also call poor whites, “White T...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1231527</th>\n",
              "      <td>f1563710d0cd93650e26</td>\n",
              "      <td>Should my 5 yr old son and 2 yr old daughter s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1284232</th>\n",
              "      <td>fbada72d37e57f01d18f</td>\n",
              "      <td>Why do we have parents?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          qid  ... target\n",
              "147144   1cc67025519a7e0d23a5  ...      0\n",
              "978379   bfabc9f014b5d3e1b08c  ...      0\n",
              "588051   73315f395204472d6afc  ...      0\n",
              "1231527  f1563710d0cd93650e26  ...      0\n",
              "1284232  fbada72d37e57f01d18f  ...      0\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hu6lFucLp4Bn"
      },
      "source": [
        "## Task 4: TensorFlow Hub for Natural Language Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dDjc3ypg1uh"
      },
      "source": [
        "Our text data consits of questions and corresponding labels.\n",
        "\n",
        "You can think of a question vector as a distributed representation of a question, and is computed for every question in the training set. The question vector along with the output label is then used to train the statistical classification model. \n",
        "\n",
        "The intuition is that the question vector captures the semantics of the question and, as a result, can be effectively used for classification. \n",
        "\n",
        "To obtain question vectors, we have two alternatives that have been used for several text classification problems in NLP: \n",
        "* word-based representations and \n",
        "* context-based representations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKLfQ-LAhdQZ"
      },
      "source": [
        "#### Word-based Representations\n",
        "\n",
        "- A **word-based representation** of a question combines word embeddings of the content words in the question. We can use the average of the word embeddings of content words in the question. Average of word embeddings have been used for different NLP tasks.\n",
        "- Examples of pre-trained embeddings include:\n",
        "  - **Word2Vec**: These are pre-trained embeddings of words learned from a large text corpora. Word2Vec has been pre-trained on a corpus of news articles with  300 million tokens, resulting in 300-dimensional vectors.\n",
        "  - **GloVe**: has been pre-trained on a corpus of tweets with 27 billion tokens, resulting in 200-dimensional vectors.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoHvyDd7i7Hx"
      },
      "source": [
        "#### Context-based Representations\n",
        "\n",
        "- **Context-based representations** may use language models to generate vectors of sentences. So, instead of learning vectors for individual words in the sentence, they compute a vector for sentences on the whole, by taking into account the order of words and the set of co-occurring words.\n",
        "- Examples of deep contextualised vectors include:\n",
        "  - **Embeddings from Language Models (ELMo)**: uses character-based word representations and bidirectional LSTMs. The pre-trained model computes a contextualised vector of 1024 dimensions. ELMo is available on Tensorflow Hub.\n",
        "  - **Universal Sentence Encoder (USE)**: The encoder uses a Transformer  architecture that uses attention mechanism to incorporate information about the order and the collection of words. The pre-trained model of USE that returns a vector of 512 dimensions is also available on Tensorflow Hub.\n",
        "  - **Neural-Net Language Model (NNLM)**: The model simultaneously learns representations of words and probability functions for word sequences, allowing it to capture semantics of a sentence. We will use a  pretrained  models available on Tensorflow Hub, that are trained on the English Google News 200B corpus, and computes a vector of 128 dimensions for the larger model and 50 dimensions for the smaller model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZrM-BpDrxUG"
      },
      "source": [
        "Tensorflow Hub provides a number of [modules](https://tfhub.dev/s?module-type=text-embedding&tf-version=tf2&q=tf2) to convert sentences into embeddings such as Universal sentence ecoders, NNLM, BERT and Wikiwords."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TOn7rWN4BW-"
      },
      "source": [
        "Transfer learning makes it possible to save training resources and to achieve good model generalization even when training on a small dataset. In this project, we will demonstrate this by training with several different TF-Hub modules."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePW3i1zos8PP"
      },
      "source": [
        "module_url = \"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\" #@param [\"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\", \"https://tfhub.dev/google/tf2-preview/nnlm-en-dim50/1\", \"https://tfhub.dev/google/tf2-preview/nnlm-en-dim128/1\", \"https://tfhub.dev/google/universal-sentence-encoder/4\", \"https://tfhub.dev/google/universal-sentence-encoder-large/5\"] {allow-input: true}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTTELVrtqPwW"
      },
      "source": [
        "## Tasks 5 & 6: Define Function to Build and Compile Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6di0eiFs8ch"
      },
      "source": [
        "def train_and_evaluate_model(module_url, embed_size, name, trainable=False):\n",
        "  \n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51YeToW1qpdi"
      },
      "source": [
        "## Task 7: Train Various Text Classification Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmKhdRH1SsXG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWfWIypew-lk"
      },
      "source": [
        "module_url = \"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\" #@param [\"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\", \"https://tfhub.dev/google/tf2-preview/nnlm-en-dim50/1\", \"https://tfhub.dev/google/tf2-preview/nnlm-en-dim128/1\", \"https://tfhub.dev/google/universal-sentence-encoder/4\", \"https://tfhub.dev/google/universal-sentence-encoder-large/5\"] {allow-input: true}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJSxiRusq6CY"
      },
      "source": [
        "## Task 8: Compare Accuracy and Loss Curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taqgWQRHTfKq"
      },
      "source": [
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "plotter = tfdocs.plots.HistoryPlotter(metric = 'accuracy')\n",
        "plotter.plot(histories)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend(bbox_to_anchor=(1.0, 1.0), loc='upper left')\n",
        "plt.title(\"Accuracy Curves for Models\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPxhmeAib7XP"
      },
      "source": [
        "plotter = tfdocs.plots.HistoryPlotter(metric = 'loss')\n",
        "plotter.plot(histories)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend(bbox_to_anchor=(1.0, 1.0), loc='upper left')\n",
        "plt.title(\"Loss Curves for Models\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54bNF4m-w08D"
      },
      "source": [
        "## Task 9: Fine-tune Model from TF Hub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxNN-MzorJ9V"
      },
      "source": [
        "## Task 10: Train Bigger Models and Visualize Metrics with TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lG6fv6Mis8xd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_Rwudlms80h"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFxWfePns83c"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsM0ZMt3s86C"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRO6Wkt4s889"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVdlhv3Ls8_6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WavvT6vs9C3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdL4FWe_s9Fj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7D9jHDdzs9IJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}